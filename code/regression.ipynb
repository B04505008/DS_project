{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load():\n",
    "    print(\"load train_x\")\n",
    "    train_x = pd.read_csv(\"./train_x.csv\")\n",
    "    print(\"load train_y\")\n",
    "    train_y = pd.read_csv(\"./train_y.csv\")\n",
    "    \n",
    "    \n",
    "    print(\"load test_x\")\n",
    "    test_x = pd.read_csv(\"./x2.csv\")\n",
    "    print(\"load test_y\")\n",
    "    test_y = pd.read_csv(\"./y2.csv\")\n",
    "    \n",
    "    print(\"loading completed\")\n",
    "    \n",
    "    print(\"train_x to array\")\n",
    "    train_x = np.array(train_x, dtype = 'float64')\n",
    "    print(\"train_y to array\")\n",
    "    train_y = np.array(train_y, dtype = 'float64')\n",
    "    \n",
    "    print(\"test_x to array\")\n",
    "    test_x = np.array(test_x, dtype = 'float64')\n",
    "    print(\"test_y to array\")\n",
    "    test_y = np.array(test_y, dtype = 'float64')\n",
    "    \n",
    "    \n",
    "    #scaler = preprocessing.StandardScaler()\n",
    "    #scaler = preprocessing.StandardScaler().fit(train_x)\n",
    "    #scaler = preprocessing.scale(train_x, axis=0, with_mean=True,with_std=True,copy=True)\n",
    "    #scaler = preprocessing.MinMaxScaler()\n",
    "    #print(scaler)\n",
    "    \n",
    "    '''train_x = scaler.fit_transform(train_x[:, np.newaxis])\n",
    "    train_y = scaler.fit_transform(train_y[:, np.newaxis])\n",
    "    test_x = scaler.fit_transform(test_x[:, np.newaxis])\n",
    "    test_y = scaler.fit_transform(test_y[:, np.newaxis])'''\n",
    "    #print(\"train_x\", train_x)\n",
    "    #print(\"train_x\", train_x.shape)\n",
    "    #scaler.fit_transform(train_x)\n",
    "    #train_x = preprocessing.scale(train_x, axis=0)\n",
    "    #train_y = preprocessing.scale(train_y, axis=0)\n",
    "    #test_x = preprocessing.scale(test_x, axis=0)\n",
    "    #test_y = preprocessing.scale(test_y, axis=0)\n",
    "    \n",
    "    \n",
    "    #train_x = scaler.transform(train_x)\n",
    "    #train_y = scaler.transform(train_y)\n",
    "    #test_x = scaler.transform(test_x)\n",
    "    #test_y = scaler.transform(test_y)\n",
    "    \n",
    "    #(train_x, train_y) = shuffle(train_x, train_y)\n",
    "    #(test_x, test_y) = shuffle(test_x, test_y)\n",
    "    #joblib.dump(scaler,'scaler.pkl')\n",
    "    \n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, filename):\n",
    "    print('saving model to ' + filename + '...')\n",
    "    pickle.dump((model), open(filename, 'wb'))\n",
    "\n",
    "def load_model(filename):\n",
    "    model = pickle.load(open(filename, 'rb'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainandtest(X_train, Y_train, X_test, Y_test):\n",
    "    #iter_times = 1000\n",
    "    #n_estimators\n",
    "    #model = XGBClassifier(max_depth=20, n_estimators=2048, learning_rate=0.01)\n",
    "    #model.fit(X_train, Y_train.flatten())\n",
    "    #model = XGBClassifier(max_depth=3, n_estimators=iter_times, learning_rate=0.01)\n",
    "    #model = XGBRegressor(max_depth=3, subsample=0.5,gamma=1, colsample_bytree=0.5, n_estimators=iter_times, learning_rate=0.01)\n",
    "    multioutputregressor = MultiOutputRegressor(GradientBoostingRegressor(n_estimators = 1000, random_state=0)).fit(X_train, Y_train)\n",
    "    #x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.1)\n",
    "    \n",
    "    #eval_set = [(x_test, y_test)]\n",
    "    #model.fit(x_train, y_train, early_stopping_rounds=iter_times*0.1, eval_metric=\"logloss\", eval_set=eval_set, verbose=True)\n",
    "    #model.fit(X_train, Y_train, eval_metric=\"rmse\", eval_set=eval_set, verbose=True)\n",
    "\n",
    "    return multioutputregressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load train_x\n",
      "load train_y\n",
      "load test_x\n",
      "load test_y\n",
      "loading completed\n",
      "train_x to array\n",
      "train_y to array\n",
      "test_x to array\n",
      "test_y to array\n",
      "(23987, 100)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = load()\n",
    "print(x_train.shape)\n",
    "model = trainandtest(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model to model_1000_GDBR...\n"
     ]
    }
   ],
   "source": [
    "file_name = \"model_1000_GDBR\"\n",
    "save_model(model, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_train [[ 0.         -0.02257174 -0.04577552 ... -0.0685374  -0.04577552\n",
      "  -0.02257174]\n",
      " [ 0.          0.0006669   0.00146662 ...  0.00239373  0.00146662\n",
      "   0.0006669 ]\n",
      " [ 0.         -0.00300334 -0.00588663 ... -0.00861987 -0.00588663\n",
      "  -0.00300334]\n",
      " ...\n",
      " [ 0.          0.00985964  0.02003843 ...  0.03003568  0.02003843\n",
      "   0.00985964]\n",
      " [ 0.         -0.00183069 -0.00366265 ... -0.00549861 -0.00366265\n",
      "  -0.00183069]\n",
      " [ 0.          0.00343141  0.00700188 ...  0.01067598  0.00700188\n",
      "   0.00343141]]\n",
      "predict_train (23987, 100)\n",
      "train_y [[-0.         -0.02275117 -0.04547991 ... -0.06816381 -0.04547991\n",
      "  -0.02275117]\n",
      " [ 0.          0.00080856  0.00161632 ...  0.00242249  0.00161632\n",
      "   0.00080856]\n",
      " [-0.         -0.00286279 -0.00572276 ... -0.00857708 -0.00572276\n",
      "  -0.00286279]\n",
      " ...\n",
      " [ 0.          0.01024973  0.02048934 ...  0.03070873  0.02048934\n",
      "   0.01024973]\n",
      " [-0.         -0.00187274 -0.00374364 ... -0.00561084 -0.00374364\n",
      "  -0.00187274]\n",
      " [ 0.          0.0036857   0.00736775 ...  0.01104254  0.00736775\n",
      "   0.0036857 ]]\n",
      "train_y (23987, 100)\n"
     ]
    }
   ],
   "source": [
    "predict_train = model.predict(x_train)\n",
    "print(\"predict_train\", predict_train)\n",
    "print(\"predict_train\", predict_train.shape)\n",
    "print(\"train_y\", y_train)\n",
    "print(\"train_y\", y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0009693591888297521\n"
     ]
    }
   ],
   "source": [
    "#print (np.mean((model.predict(x_train) - y_train)**2, axis=0))\n",
    "print (np.mean(np.mean((predict_train - y_train)**2, axis=0)**(0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_test [[ 0.         -0.03019398 -0.06165073 ... -0.09342777 -0.06165073\n",
      "  -0.03019398]\n",
      " [ 0.         -0.03019398 -0.06165073 ... -0.09342777 -0.06165073\n",
      "  -0.03019398]\n",
      " [ 0.         -0.03019398 -0.06165073 ... -0.09342777 -0.06165073\n",
      "  -0.03019398]\n",
      " ...\n",
      " [ 0.         -0.00054304 -0.00117698 ... -0.00180642 -0.00117698\n",
      "  -0.00054304]\n",
      " [ 0.         -0.00054304 -0.00117698 ... -0.00180642 -0.00117698\n",
      "  -0.00054304]\n",
      " [ 0.         -0.00054304 -0.00117698 ... -0.00180642 -0.00117698\n",
      "  -0.00054304]]\n",
      "predict_test (3998, 100)\n",
      "test_y [[-0.         -0.03134882 -0.0626667  ... -0.09392273 -0.0626667\n",
      "  -0.03134882]\n",
      " [-0.         -0.03131789 -0.06260488 ... -0.09383008 -0.06260488\n",
      "  -0.03131789]\n",
      " [-0.         -0.031287   -0.06254312 ... -0.09373752 -0.06254312\n",
      "  -0.031287  ]\n",
      " ...\n",
      " [-0.         -0.00060791 -0.00121522 ... -0.00182133 -0.00121522\n",
      "  -0.00060791]\n",
      " [-0.         -0.00060731 -0.00121402 ... -0.00181953 -0.00121402\n",
      "  -0.00060731]\n",
      " [-0.         -0.00060671 -0.00121282 ... -0.00181774 -0.00121282\n",
      "  -0.00060671]]\n",
      "test_y (3998, 100)\n"
     ]
    }
   ],
   "source": [
    "predict_test = model.predict(x_test)\n",
    "print(\"predict_test\", predict_test)\n",
    "print(\"predict_test\", predict_test.shape)\n",
    "print(\"test_y\", y_test)\n",
    "print(\"test_y\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0008469697230707675\n"
     ]
    }
   ],
   "source": [
    "#print (np.mean((model.predict(x_test) - y_test)**2, axis=0))\n",
    "print (np.mean(np.mean((predict_test - y_test)**2, axis=0)**(0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
